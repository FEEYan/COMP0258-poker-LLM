{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prediction accuracy: 0.4120\n",
      "Accuracy for fold: 0.4440 (111/250)\n",
      "Accuracy for check: 0.0000 (0/250)\n",
      "Accuracy for call: 0.8880 (222/250)\n",
      "Accuracy for raise: 0.3160 (79/250)\n",
      "RMSE for raise amounts: 5.4267\n",
      "NRMSE for raise amounts: 0.4174\n",
      "Action prediction accuracy: 0.5240\n",
      "Accuracy for fold: 0.5960 (149/250)\n",
      "Accuracy for check: 0.1880 (47/250)\n",
      "Accuracy for call: 0.7680 (192/250)\n",
      "Accuracy for raise: 0.5440 (136/250)\n",
      "RMSE for raise amounts: 59.0208\n",
      "NRMSE for raise amounts: 3.2789\n",
      "Action prediction accuracy: 0.2510\n",
      "Accuracy for fold: 0.0000 (0/250)\n",
      "Accuracy for check: 0.0000 (0/250)\n",
      "Accuracy for call: 1.0000 (250/250)\n",
      "Accuracy for raise: 0.0040 (1/250)\n",
      "RMSE for raise amounts: 2.0000\n",
      "NRMSE for raise amounts: inf\n",
      "Action prediction accuracy: 0.4750\n",
      "Accuracy for fold: 0.7640 (191/250)\n",
      "Accuracy for check: 0.4800 (120/250)\n",
      "Accuracy for call: 0.4400 (110/250)\n",
      "Accuracy for raise: 0.2160 (54/250)\n",
      "RMSE for raise amounts: 26.6451\n",
      "NRMSE for raise amounts: 1.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hn/7m7y7w415bs1pcsbqy68slhm0000gn/T/ipykernel_5968/678810063.py:118: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  nrmse = rmse / true_amount_range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action prediction accuracy: 0.2910\n",
      "Accuracy for fold: 0.0000 (0/250)\n",
      "Accuracy for check: 0.0000 (0/250)\n",
      "Accuracy for call: 0.9840 (246/250)\n",
      "Accuracy for raise: 0.1800 (45/250)\n",
      "RMSE for raise amounts: 18.5475\n",
      "NRMSE for raise amounts: 18.5475\n",
      "Action prediction accuracy: 0.6540\n",
      "Accuracy for fold: 0.5960 (149/250)\n",
      "Accuracy for check: 1.0000 (250/250)\n",
      "Accuracy for call: 0.7040 (176/250)\n",
      "Accuracy for raise: 0.3160 (79/250)\n",
      "RMSE for raise amounts: 51.5834\n",
      "NRMSE for raise amounts: 2.3341\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import argparse\n",
    "\n",
    "\n",
    "def clean_prediction(text):\n",
    "    \"\"\"Clean the prediction text by removing <end_of_turn> and <pad> tags.\"\"\"\n",
    "    text = text.replace(\"<end_of_turn>\\n<pad>\", \"\").strip()\n",
    "    text = text.replace(\"<end_of_turn>\", \"\").strip()\n",
    "    text = text.replace(\" chips\", \"\").strip()\n",
    "    text = text.replace(\".\", \"\").strip()\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def extract_action(move):\n",
    "    \"\"\"Extract the action (call, fold, check, raise) from a move.\"\"\"\n",
    "    if pd.isna(move):\n",
    "        return np.nan\n",
    "    if \"raise\" in move:\n",
    "        return \"raise\"\n",
    "    elif \"call\" in move:\n",
    "        return \"call\"\n",
    "    elif \"check\" in move:\n",
    "        return \"check\"\n",
    "    elif \"fold\" in move:\n",
    "        return \"fold\"\n",
    "    else:\n",
    "        return move\n",
    "\n",
    "\n",
    "def extract_amount(move):\n",
    "    \"\"\"Extract the bet amount from a raise move.\"\"\"\n",
    "    if pd.isna(move):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(move.split(\"raise\")[1].strip())\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def main(model_name):\n",
    "    # Load the CSV file based on the model name\n",
    "    file_path = f'/Users/weber/Github/COMP0258/testing-results/{model_name}_predictions.csv'\n",
    "    if file_path is None:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "    else:\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "    # Clean predictions\n",
    "    df['Prediction_Clean'] = df['Prediction'].apply(clean_prediction)\n",
    "    df['Ground_Truth_Clean'] = df['Ground Truth']\n",
    "\n",
    "    # Extract action and amount\n",
    "    df['Pred_Action'] = df['Prediction_Clean'].apply(extract_action)\n",
    "    df['True_Action'] = df['Ground_Truth_Clean'].apply(extract_action)\n",
    "    df['Pred_Amount'] = df['Prediction_Clean'].apply(extract_amount)\n",
    "    df['True_Amount'] = df['Ground_Truth_Clean'].apply(extract_amount)\n",
    "\n",
    "    # save the cleaned dataframe\n",
    "    cleaned_file_path = f'/Users/weber/Github/COMP0258/testing-results/{model_name}_cleaned.csv'\n",
    "    df[['Pred_Action', 'True_Action', 'Pred_Amount', 'True_Amount']].to_csv(\n",
    "        cleaned_file_path, index=False)\n",
    "\n",
    "    # Calculate overall accuracy for the action type\n",
    "    action_accuracy = accuracy_score(df['True_Action'], df['Pred_Action'])\n",
    "    print(f\"Action prediction accuracy: {action_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    # Confusion matrix for actions\n",
    "    actions = ['fold', 'check', 'call', 'raise']\n",
    "    action_df = df[df['True_Action'].isin(\n",
    "        actions) & df['Pred_Action'].isin(actions)]\n",
    "    cm = confusion_matrix(\n",
    "        action_df['True_Action'], action_df['Pred_Action'], labels=actions)\n",
    "    cm_df = pd.DataFrame(cm, index=actions, columns=actions)\n",
    "\n",
    "    # Calculate per-action accuracy\n",
    "    action_specific_accuracy = {}\n",
    "    for action in actions:\n",
    "        action_rows = df[df['True_Action'] == action]\n",
    "        if len(action_rows) > 0:\n",
    "            correct = sum(action_rows['Pred_Action'] == action)\n",
    "            accuracy = correct / len(action_rows)\n",
    "            action_specific_accuracy[action] = accuracy\n",
    "            print(\n",
    "                f\"Accuracy for {action}: {accuracy:.4f} ({correct}/{len(action_rows)})\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    # adding title for the confusion matrix\n",
    "    plt.suptitle(f'{model_name}', fontsize=20)\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix for Poker Actions')\n",
    "    plt.ylabel('True Action')\n",
    "    plt.xlabel('Predicted Action')\n",
    "\n",
    "    # Analyze raise amount accuracy\n",
    "    raise_df = df[(df['True_Action'] == 'raise') &\n",
    "                  (df['Pred_Action'] == 'raise')]\n",
    "    raise_df = raise_df.dropna(subset=['True_Amount', 'Pred_Amount'])\n",
    "\n",
    "    if len(raise_df) > 0:\n",
    "        # Calculate RMSE for raise amounts\n",
    "        rmse = np.sqrt(\n",
    "            ((raise_df['True_Amount'] - raise_df['Pred_Amount']) ** 2).mean())\n",
    "        print(f\"RMSE for raise amounts: {rmse:.4f}\")\n",
    "\n",
    "        # Calculate NRMSE for raise amounts\n",
    "        true_amount_range = raise_df['True_Amount'].max(\n",
    "        ) - raise_df['True_Amount'].min()\n",
    "        nrmse = rmse / true_amount_range\n",
    "        print(f\"NRMSE for raise amounts: {nrmse:.4f}\")\n",
    "\n",
    "        # Plot raise amount comparison\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(raise_df['True_Amount'],\n",
    "                    raise_df['Pred_Amount'], alpha=0.6)\n",
    "\n",
    "        # Add perfect prediction line\n",
    "        max_val = max(raise_df['True_Amount'].max(),\n",
    "                      raise_df['Pred_Amount'].max())\n",
    "        min_val = min(raise_df['True_Amount'].min(),\n",
    "                      raise_df['Pred_Amount'].min())\n",
    "        plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "\n",
    "        plt.title('Raise Amount: Predicted vs True')\n",
    "        plt.xlabel('True Raise Amount')\n",
    "        plt.ylabel('Predicted Raise Amount')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Save the combined image\n",
    "    combined_image_path = f'/Users/weber/Github/COMP0258/testing-results/{model_name}_confusion-matrix.png'\n",
    "\n",
    "    # Add accuracy information to the plot\n",
    "    accuracy_text = f\"Action accuracy: {action_accuracy:.2f}\"\n",
    "\n",
    "    # Add per-action accuracy to the text\n",
    "    for action in actions:\n",
    "        if action in action_specific_accuracy:\n",
    "            accuracy_text += f\" | {action.capitalize()} accuracy: {action_specific_accuracy[action]:.2f}\"\n",
    "\n",
    "    # Add RMSE to the text if available\n",
    "    if len(raise_df) > 0:\n",
    "        accuracy_text += f\" | RMSE for raise amounts: {rmse:.2f}\"\n",
    "    plt.figtext(0.5, 0.01, accuracy_text, ha=\"center\", fontsize=12)\n",
    "\n",
    "    plt.savefig(combined_image_path)\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parser = argparse.ArgumentParser(\n",
    "    #     description='Evaluate poker move predictions.')\n",
    "    # parser.add_argument('model_name', type=str,\n",
    "    #                     help='The name of the model to evaluate (e.g., gemma-2-9b-it, lora-gemma-2-9b-it)')\n",
    "    # args = parser.parse_args()\n",
    "    # main(args.model_name)\n",
    "    models = ['gemma-2-9b-it', 'lora-gemma-2-9b-it',\n",
    "              'Qwen2.5-7B-Instruct-1M', 'lora-Qwen2.5-7B-Instruct-1M',\n",
    "              'Meta-Llama-3.1-8B-Instruct', 'lora-Meta-Llama-3.1-8B-Instruct']\n",
    "    for model in models:\n",
    "        main(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
