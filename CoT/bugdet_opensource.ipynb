{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Get current directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# Set your Hugging Face API token here\n",
    "hf_token = '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'\n",
    "\n",
    "# Read the test sets\n",
    "with open(os.path.join(cwd, \"Postflop 100 Sample.json\"), \"r\") as f:\n",
    "    postflop_test_set = json.load(f)\n",
    "\n",
    "with open(os.path.join(cwd, \"Preflop 100 Sample.json\"), \"r\") as f:\n",
    "    preflop_test_set = json.load(f)\n",
    "\n",
    "# Combine both test sets (if needed) into one list\n",
    "all_examples = postflop_test_set + preflop_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_instruction = '''\n",
    "You are an expert in 6-handed No Limit Texas Holdem. Your job is to analyze a game scenario and decide on the optimal action.\n",
    "\n",
    "Think through your answer step-by-step and then output exactly one sentence starting with \"Final Answer:\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example 1/200\n",
      "Processing example 2/200\n",
      "Processing example 3/200\n",
      "Processing example 4/200\n",
      "Processing example 5/200\n",
      "Processing example 6/200\n",
      "Processing example 7/200\n",
      "Processing example 8/200\n",
      "Processing example 9/200\n",
      "Processing example 10/200\n",
      "Processing example 11/200\n",
      "Processing example 12/200\n",
      "Processing example 13/200\n",
      "Processing example 14/200\n",
      "Processing example 15/200\n",
      "Processing example 16/200\n",
      "Processing example 17/200\n",
      "Processing example 18/200\n",
      "Processing example 19/200\n",
      "Processing example 20/200\n",
      "Processing example 21/200\n",
      "Processing example 22/200\n",
      "Processing example 23/200\n",
      "Processing example 24/200\n",
      "Processing example 25/200\n",
      "Processing example 26/200\n",
      "Processing example 27/200\n",
      "Processing example 28/200\n",
      "Processing example 29/200\n",
      "Processing example 30/200\n",
      "Processing example 31/200\n",
      "Processing example 32/200\n",
      "Processing example 33/200\n",
      "Processing example 34/200\n",
      "Processing example 35/200\n",
      "Processing example 36/200\n",
      "Processing example 37/200\n",
      "Processing example 38/200\n",
      "Processing example 39/200\n",
      "Processing example 40/200\n",
      "Processing example 41/200\n",
      "Processing example 42/200\n",
      "Processing example 43/200\n",
      "Processing example 44/200\n",
      "Processing example 45/200\n",
      "Processing example 46/200\n",
      "Processing example 47/200\n",
      "Processing example 48/200\n",
      "Processing example 49/200\n",
      "Processing example 50/200\n",
      "Processing example 51/200\n",
      "Processing example 52/200\n",
      "Processing example 53/200\n",
      "Processing example 54/200\n",
      "Processing example 55/200\n",
      "Processing example 56/200\n",
      "Processing example 57/200\n",
      "Processing example 58/200\n",
      "Processing example 59/200\n",
      "Processing example 60/200\n",
      "Processing example 61/200\n",
      "Processing example 62/200\n",
      "Processing example 63/200\n",
      "Processing example 64/200\n",
      "Processing example 65/200\n",
      "Processing example 66/200\n",
      "Processing example 67/200\n",
      "Processing example 68/200\n",
      "Processing example 69/200\n",
      "Processing example 70/200\n",
      "Processing example 71/200\n",
      "Processing example 72/200\n",
      "Processing example 73/200\n",
      "Processing example 74/200\n",
      "Processing example 75/200\n",
      "Processing example 76/200\n",
      "Processing example 77/200\n",
      "Processing example 78/200\n",
      "Processing example 79/200\n",
      "Processing example 80/200\n",
      "Processing example 81/200\n",
      "Processing example 82/200\n",
      "Processing example 83/200\n",
      "Processing example 84/200\n",
      "Processing example 85/200\n",
      "Processing example 86/200\n",
      "Processing example 87/200\n",
      "Processing example 88/200\n",
      "Processing example 89/200\n",
      "Processing example 90/200\n",
      "Processing example 91/200\n",
      "Processing example 92/200\n",
      "Processing example 93/200\n",
      "Processing example 94/200\n",
      "Processing example 95/200\n",
      "Processing example 96/200\n",
      "Processing example 97/200\n",
      "Processing example 98/200\n",
      "Processing example 99/200\n",
      "Processing example 100/200\n",
      "Processing example 101/200\n",
      "Processing example 102/200\n",
      "Processing example 103/200\n",
      "Processing example 104/200\n",
      "Processing example 105/200\n",
      "Processing example 106/200\n",
      "Processing example 107/200\n",
      "Processing example 108/200\n",
      "Processing example 109/200\n",
      "Processing example 110/200\n",
      "Processing example 111/200\n",
      "Processing example 112/200\n",
      "Processing example 113/200\n",
      "Processing example 114/200\n",
      "Processing example 115/200\n",
      "Processing example 116/200\n",
      "Processing example 117/200\n",
      "Processing example 118/200\n",
      "Processing example 119/200\n",
      "Processing example 120/200\n",
      "Processing example 121/200\n",
      "Processing example 122/200\n",
      "Processing example 123/200\n",
      "Processing example 124/200\n",
      "Processing example 125/200\n",
      "Processing example 126/200\n",
      "Processing example 127/200\n",
      "Processing example 128/200\n",
      "Processing example 129/200\n",
      "Processing example 130/200\n",
      "Processing example 131/200\n",
      "Processing example 132/200\n",
      "Processing example 133/200\n",
      "Processing example 134/200\n",
      "Processing example 135/200\n",
      "Processing example 136/200\n",
      "Processing example 137/200\n",
      "Processing example 138/200\n",
      "Processing example 139/200\n",
      "Processing example 140/200\n",
      "Processing example 141/200\n",
      "Processing example 142/200\n",
      "Processing example 143/200\n",
      "Processing example 144/200\n",
      "Processing example 145/200\n",
      "Processing example 146/200\n",
      "Processing example 147/200\n",
      "Processing example 148/200\n",
      "Processing example 149/200\n",
      "Processing example 150/200\n",
      "Processing example 151/200\n",
      "Processing example 152/200\n",
      "Processing example 153/200\n",
      "Processing example 154/200\n",
      "Processing example 155/200\n",
      "Processing example 156/200\n",
      "Processing example 157/200\n",
      "Processing example 158/200\n",
      "Processing example 159/200\n",
      "Processing example 160/200\n",
      "Processing example 161/200\n",
      "Processing example 162/200\n",
      "Processing example 163/200\n",
      "Processing example 164/200\n",
      "Processing example 165/200\n",
      "Processing example 166/200\n",
      "Processing example 167/200\n",
      "Processing example 168/200\n",
      "Processing example 169/200\n",
      "Processing example 170/200\n",
      "Processing example 171/200\n",
      "Processing example 172/200\n",
      "Processing example 173/200\n",
      "Processing example 174/200\n",
      "Processing example 175/200\n",
      "Processing example 176/200\n",
      "Processing example 177/200\n",
      "Processing example 178/200\n",
      "Processing example 179/200\n",
      "Processing example 180/200\n",
      "Processing example 181/200\n",
      "Processing example 182/200\n",
      "Processing example 183/200\n",
      "Processing example 184/200\n",
      "Processing example 185/200\n",
      "Processing example 186/200\n",
      "Processing example 187/200\n",
      "Processing example 188/200\n",
      "Processing example 189/200\n",
      "Processing example 190/200\n",
      "Processing example 191/200\n",
      "Processing example 192/200\n",
      "Processing example 193/200\n",
      "Processing example 194/200\n",
      "Processing example 195/200\n",
      "Processing example 196/200\n",
      "Processing example 197/200\n",
      "Processing example 198/200\n",
      "Processing example 199/200\n",
      "Processing example 200/200\n",
      "Saved outputs to Poker_Llama-31-8B_budget_4096.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "max_rounds = 8\n",
    "max_tokens_set = [4096]\n",
    "client_hf = InferenceClient(api_key=hf_token)\n",
    "\n",
    "for max_tokens in max_tokens_set:\n",
    "    for idx, example in enumerate(all_examples):\n",
    "        prompt_text = example.get(\"instruction\", \"\")\n",
    "        prompt_text = prompt_text.replace(\"Do not explain your answer.\", \"\").strip()\n",
    "        prompt = extra_instruction + prompt_text\n",
    "        accumulated_reasoning = \"\"\n",
    "        current_prompt = prompt\n",
    "        used_tokens = 0\n",
    "        max_toks = max_tokens\n",
    "\n",
    "        # Print the current example being processed\n",
    "        print(f\"Processing example {idx+1}/{len(all_examples)}\")\n",
    "        for i in range(max_rounds):\n",
    "            response = client_hf.chat_completion(\n",
    "                model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "                messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are an expert at Texas Holdem Poker. Your job is to do step-by-step reasoning about a game scenario and then provide a final answer as 'Final Answer:'.\"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt_text}\n",
    "        ],\n",
    "                max_tokens=max_toks,\n",
    "                temperature=0.0\n",
    "            )\n",
    "            new_output = response.choices[0].message.content.strip()\n",
    "            accumulated_reasoning += \"\\n\" + new_output\n",
    "            used_tokens += response.usage.total_tokens\n",
    "\n",
    "            if used_tokens >= max_tokens:\n",
    "                break\n",
    "\n",
    "            # Strip final answer fi given\n",
    "            if \"Final Answer:\" in new_output:\n",
    "                new_output = new_output.split(\"Final Answer:\")[0].strip()\n",
    "\n",
    "            current_prompt = prompt + accumulated_reasoning + \"\\nStep-by-step, continue reasoning:\"\n",
    "\n",
    "            # Decrease max tokens for next round\n",
    "            max_toks = max_tokens - used_tokens\n",
    "\n",
    "        # Prompt for final answer\n",
    "        final_prompt = prompt + accumulated_reasoning + (\n",
    "            f\"\\nNow, based on your reasoning, provide a final decision.\\n\"\n",
    "            f\"\\nFinal Answer: \"\n",
    "        )\n",
    "\n",
    "        response = client_hf.chat_completion(\n",
    "            model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "            messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert at Texas Holdem Poker. Your job is to do step-by-step reasoning about a game scenario and then provide a final answer as 'Final Answer:'.\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ],\n",
    "            max_tokens=10,\n",
    "            temperature=0.0\n",
    "        )\n",
    "        final_output = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Extract final answer\n",
    "        final_answer = final_output.strip().split()[0]\n",
    "\n",
    "        results.append({\n",
    "            \"instruction\": example.get(\"instruction\", \"\"),\n",
    "            \"ground_truth\": example.get(\"output\", \"\"),\n",
    "            \"full_trace\": final_prompt + final_output,\n",
    "            \"reasoning\": accumulated_reasoning.strip(),\n",
    "            \"final_answer\": final_answer\n",
    "        })\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Create a DataFrame and save to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    csv_filename = f\"Poker_Llama-31-8B_budget_{max_tokens}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved outputs to {csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
