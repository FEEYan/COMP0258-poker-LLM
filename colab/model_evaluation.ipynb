{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8a461541ab4492fb6a9ea3ad7c8418e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_513537cafc7e4975bd35ed5fbe7755b7",
              "IPY_MODEL_103a0554e01d42c5b1c9fa43a2e89e64",
              "IPY_MODEL_de2fe6227d9f49188b81a2f3e9ea76c9"
            ],
            "layout": "IPY_MODEL_cd93395928b74bbfb88d7131adae1ad3"
          }
        },
        "513537cafc7e4975bd35ed5fbe7755b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aed9603fe194c68b04ed7da5e64468f",
            "placeholder": "​",
            "style": "IPY_MODEL_494e67ae294f4edf92fe39f4b82fabd9",
            "value": "Downloading shards: 100%"
          }
        },
        "103a0554e01d42c5b1c9fa43a2e89e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195341f6d18b4e11a94a64859611abdf",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35160a74c28a4227b132218884832e13",
            "value": 2
          }
        },
        "de2fe6227d9f49188b81a2f3e9ea76c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2044ac03a85146af8b3ad647ef3a5fe1",
            "placeholder": "​",
            "style": "IPY_MODEL_eab80abbfd114413ba4036274611919b",
            "value": " 2/2 [01:58&lt;00:00, 60.16s/it]"
          }
        },
        "cd93395928b74bbfb88d7131adae1ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aed9603fe194c68b04ed7da5e64468f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494e67ae294f4edf92fe39f4b82fabd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195341f6d18b4e11a94a64859611abdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35160a74c28a4227b132218884832e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2044ac03a85146af8b3ad647ef3a5fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab80abbfd114413ba4036274611919b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f0eb934fa1e4efabda3d6ba94d407e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24deeda905534a54b91426138d5d1cd0",
              "IPY_MODEL_fb565ab2ea0943c99f86617d203788fb",
              "IPY_MODEL_17496d9e10854f2489625ff2c4ebfb9a"
            ],
            "layout": "IPY_MODEL_0b175bd40882492289674057ee1b34b5"
          }
        },
        "24deeda905534a54b91426138d5d1cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0936fde92a3e48f9bde9673f56158957",
            "placeholder": "​",
            "style": "IPY_MODEL_6dc7425b541d4daabe871bf87d79b474",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fb565ab2ea0943c99f86617d203788fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c604eb25492a42679358a9ec35ec135b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6473e245a16c425ea8d2958b66a241a8",
            "value": 2
          }
        },
        "17496d9e10854f2489625ff2c4ebfb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50445a83182847aeab7f88d7754dc94b",
            "placeholder": "​",
            "style": "IPY_MODEL_4829675dab7048338e93a98dbfbf57cf",
            "value": " 2/2 [00:45&lt;00:00, 22.66s/it]"
          }
        },
        "0b175bd40882492289674057ee1b34b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0936fde92a3e48f9bde9673f56158957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc7425b541d4daabe871bf87d79b474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c604eb25492a42679358a9ec35ec135b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6473e245a16c425ea8d2958b66a241a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50445a83182847aeab7f88d7754dc94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4829675dab7048338e93a98dbfbf57cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weber50432/COMP0258-poker-LLM/blob/master/colab/model_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEZZKaYBbbP9",
        "outputId": "7460c107-9151-4d08-e685-fd1c48b94f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# Define the path to the models directory in Google Drive\n",
        "models_dir = '/content/drive/MyDrive/models'\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(models_dir):\n",
        "    # If it doesn't exist, create it\n",
        "    os.makedirs(models_dir)\n",
        "output_dir = '/content/drive/MyDrive/outputs'\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "    # If it doesn't exist, create it\n",
        "    os.makedirs(output_dir)\n",
        "data_dir = '/content/drive/MyDrive/data'\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(data_dir):\n",
        "    # If it doesn't exist, error log\n",
        "    print(\"data directory not found\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Normally using pip install unsloth is enough\n",
        "\n",
        "if True:\n",
        "    # Temporarily as of Jan 31st 2025, Colab has some issues with Pytorch\n",
        "    # Using pip install unsloth will take 3 minutes, whilst the below takes <1 minute:\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "RBTSzur4cKNi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from tqdm import tqdm\n",
        "from transformers import TextStreamer\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "QOp85ydzdg9i",
        "outputId": "4b6a2222-6c5e-4fa4-ade6-ee002348f8aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "usning_custom_dataset = True\n",
        "models_dir = \"unsloth\"\n",
        "pretrained_model_name = \"qwen2.5-14b-instruct-bnb-4bit\"\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n"
      ],
      "metadata": {
        "id": "cACep_-6dZrq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = f\"{models_dir}/{pretrained_model_name}\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# prompt = You MUST copy from above!\n",
        "prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    prompt.format(\n",
        "        \"You are a specialist in playing 6-handed No Limit Texas Holdem. The following will be a game scenario and you need to make the optimal decision.\\n\\nHere is a game summary:\\n\\nThe small blind is 0.5 chips and the big blind is 1 chips. Everyone started with 100 chips.\\nThe player positions involved in this game are UTG, HJ, CO, BTN, SB, BB.\\nIn this hand, your position is CO, and your holding is [Ace of Heart and King of Heart].\\nYou currently have High Card(Ace-high).\\nBefore the flop, CO raise 2.3, and BB raise 13.5. Assume that all other players that is not mentioned folded.\\n\\nNow it is your turn to make a move.\\nTo remind you, the current pot size is 16.3 chips, and your holding is [Ace of Heart and King of Heart].\\n\\nDecide on an action based on the strength of your hand on this board, your position, and actions before you. Do not explain your answer.\\nYour optimal action is:\"\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655,
          "referenced_widgets": [
            "b8a461541ab4492fb6a9ea3ad7c8418e",
            "513537cafc7e4975bd35ed5fbe7755b7",
            "103a0554e01d42c5b1c9fa43a2e89e64",
            "de2fe6227d9f49188b81a2f3e9ea76c9",
            "cd93395928b74bbfb88d7131adae1ad3",
            "3aed9603fe194c68b04ed7da5e64468f",
            "494e67ae294f4edf92fe39f4b82fabd9",
            "195341f6d18b4e11a94a64859611abdf",
            "35160a74c28a4227b132218884832e13",
            "2044ac03a85146af8b3ad647ef3a5fe1",
            "eab80abbfd114413ba4036274611919b",
            "2f0eb934fa1e4efabda3d6ba94d407e0",
            "24deeda905534a54b91426138d5d1cd0",
            "fb565ab2ea0943c99f86617d203788fb",
            "17496d9e10854f2489625ff2c4ebfb9a",
            "0b175bd40882492289674057ee1b34b5",
            "0936fde92a3e48f9bde9673f56158957",
            "6dc7425b541d4daabe871bf87d79b474",
            "c604eb25492a42679358a9ec35ec135b",
            "6473e245a16c425ea8d2958b66a241a8",
            "50445a83182847aeab7f88d7754dc94b",
            "4829675dab7048338e93a98dbfbf57cf"
          ]
        },
        "id": "ltJnst1EcKtL",
        "outputId": "a87adf2c-dc70-4151-bc68-8164f81c51fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8a461541ab4492fb6a9ea3ad7c8418e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f0eb934fa1e4efabda3d6ba94d407e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instruction:\n",
            "You are a specialist in playing 6-handed No Limit Texas Holdem. The following will be a game scenario and you need to make the optimal decision.\n",
            "\n",
            "Here is a game summary:\n",
            "\n",
            "The small blind is 0.5 chips and the big blind is 1 chips. Everyone started with 100 chips.\n",
            "The player positions involved in this game are UTG, HJ, CO, BTN, SB, BB.\n",
            "In this hand, your position is CO, and your holding is [Ace of Heart and King of Heart].\n",
            "You currently have High Card(Ace-high).\n",
            "Before the flop, CO raise 2.3, and BB raise 13.5. Assume that all other players that is not mentioned folded.\n",
            "\n",
            "Now it is your turn to make a move.\n",
            "To remind you, the current pot size is 16.3 chips, and your holding is [Ace of Heart and King of Heart].\n",
            "\n",
            "Decide on an action based on the strength of your hand on this board, your position, and actions before you. Do not explain your answer.\n",
            "Your optimal action is:\n",
            "\n",
            "### Response:\n",
            "Fold\n",
            "\n",
            "### Rationale:\n",
            "Given the strength of the hand (AK), the aggressive raising by the big blind (BB) might indicate a very strong hand such as AA, KK, or QQ. Considering the size of the raise (13.5 chips), which is significantly larger than the initial raise (2.3 chips), it's likely the BB has a premium hand. Folding here minimizes potential losses against a likely strong hand. Allowing the BB to win the pot preflop is the best course of action given the circumstances. \n",
            "\n",
            "However, since explicit explanations were asked to be avoided, the provided response is simply \"Fold\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    # inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = prompt.format(instruction, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "if usning_custom_dataset:\n",
        "    # open a json file from data_dir\n",
        "    with open(f'{data_dir}/poker-preflop/preflop_1k_test_set_prompt_and_label.json', 'r') as f:\n",
        "            preflop_dataset = json.load(f)\n",
        "    print(f\"reading {len(preflop_dataset)} preflop data.\")\n",
        "    with open(f'{data_dir}/poker-postflop/postflop_10k_test_set_prompt_and_label.json', 'r') as f:\n",
        "            postflop_dataset = json.load(f)\n",
        "    print(f\"reading {len(postflop_dataset)} preflop data.\")\n",
        "else:\n",
        "    dataset = load_dataset(\"RZ412/PokerBench\", split = \"test\")\n",
        "    dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snSDRfbed9SB",
        "outputId": "b7d2950e-a6e0-4515-f286-d7b067a6a196"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading 1000 preflop data.\n",
            "reading 10000 preflop data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing a radom sample"
      ],
      "metadata": {
        "id": "7x9t6RMXk9eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not usning_custom_dataset:\n",
        "    print(\"Processing hg dataset.\")\n",
        "    index = random.randint(0, len(dataset))\n",
        "    print(\"Groud truth: \",dataset[index]['output'])\n",
        "    inputs = tokenizer([prompt.format(dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "else:\n",
        "    print(\"Processing custom dataset.\")\n",
        "    index = random.randint(0, len(preflop_dataset))\n",
        "    print(\"Groud truth: \",preflop_dataset[index]['output'])\n",
        "    inputs = tokenizer([prompt.format(preflop_dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "# text_streamer = TextStreamer(tokenizer)\n",
        "# outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 10)\n",
        "outputs = model.generate(**inputs, max_new_tokens = 10)\n",
        "\n",
        "generated_text = tokenizer.batch_decode(outputs)[0]\n",
        "generated_text = generated_text.split(\"### Response:\")[1].strip()\n",
        "generated_text = generated_text.replace(EOS_TOKEN, \"\")\n",
        "print(\"Prediction: \",generated_text) # Print the generated text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DogBVbq7exfK",
        "outputId": "6388e53f-0752-45aa-93d3-49b7a458d263"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing custom dataset.\n",
            "Groud truth:  call\n",
            "Prediction:  Call (11 chips) to see the flop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not usning_custom_dataset:\n",
        "    ground_truths = []\n",
        "    predictions = []\n",
        "    for index in tqdm(range(len(dataset)), desc=\"Processing hg dataset\"):\n",
        "        # print(dataset[index]['output'])\n",
        "        ground_truths.append(dataset[index]['output'])\n",
        "        inputs = tokenizer([prompt.format(dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens = 10)\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "        response = response.split(\"### Response:\")[1].strip()\n",
        "        response = response.replace(EOS_TOKEN, \"\")\n",
        "        # print(response)\n",
        "        predictions.append(response)\n",
        "        # break\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "    \"Prediction\": predictions,\n",
        "    \"Ground Truth\": ground_truths\n",
        "    })\n",
        "    # Save the DataFrames to CSV files\n",
        "    results_df.to_csv(f\"{output_dir}/{pretrained_model_name}_total_predictions.csv\", index=False)\n",
        "\n",
        "else:\n",
        "    preflop_ground_truths = []\n",
        "    preflop_predictions = []\n",
        "    for index in tqdm(range(len(preflop_dataset)), desc=\"Processing custom preflop dataset\"):\n",
        "        # print(dataset[index]['output'])\n",
        "        preflop_ground_truths.append(preflop_dataset[index]['output'])\n",
        "        inputs = tokenizer([prompt.format(preflop_dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens = 10)\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "        response = response.split(\"### Response:\")[1].strip()\n",
        "        response = response.replace(EOS_TOKEN, \"\")\n",
        "        # print(response)\n",
        "        preflop_predictions.append(response)\n",
        "        # break\n",
        "    preflop_results_df = pd.DataFrame({\n",
        "    \"Prediction\": preflop_predictions,\n",
        "    \"Ground Truth\": preflop_ground_truths\n",
        "    })\n",
        "    preflop_results_df.to_csv(f\"{output_dir}/{pretrained_model_name}_preflop_predictions.csv\", index=False)\n",
        "\n",
        "\n",
        "    postflop_ground_truths = []\n",
        "    postflop_predictions = []\n",
        "    save_interval = 1000\n",
        "    output_file = f\"{output_dir}/{pretrained_model_name}_postflop_predictions.csv\"\n",
        "\n",
        "    for index in tqdm(range(len(postflop_dataset)), desc=\"Processing custom postflop dataset\"):\n",
        "        postflop_ground_truths.append(postflop_dataset[index]['output'])\n",
        "\n",
        "        inputs = tokenizer([prompt.format(postflop_dataset[index]['instruction'], \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "        response = response.split(\"### Response:\")[1].strip()\n",
        "        response = response.replace(EOS_TOKEN, \"\")\n",
        "\n",
        "        postflop_predictions.append(response)\n",
        "\n",
        "        if (index + 1) % save_interval == 0 or (index + 1) == len(postflop_dataset):\n",
        "            postflop_results_df = pd.DataFrame({\n",
        "                \"Prediction\": postflop_predictions,\n",
        "                \"Ground Truth\": postflop_ground_truths\n",
        "            })\n",
        "            postflop_results_df.to_csv(output_file, index=False)\n",
        "            print(f\"Saved progress at iteration {index + 1}\")\n",
        "\n",
        "    print(\"Processing completed.\")"
      ],
      "metadata": {
        "id": "jslsYFrLkKYM",
        "outputId": "188bb61c-8b3a-407f-fdbb-f63512a822dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom preflop dataset: 100%|██████████| 1000/1000 [27:03<00:00,  1.62s/it]\n",
            "Processing custom postflop dataset:  10%|█         | 1000/10000 [30:26<4:40:41,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  20%|██        | 2000/10000 [1:00:50<4:07:03,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  30%|███       | 3000/10000 [1:31:19<3:36:35,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  40%|████      | 4000/10000 [2:01:47<3:04:50,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  45%|████▌     | 4528/10000 [2:17:53<2:48:59,  1.85s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not usning_custom_dataset:\n",
        "    print(ground_truths)\n",
        "    print(predictions)\n",
        "else:\n",
        "    print(preflop_ground_truths)\n",
        "    print(preflop_predictions)\n",
        "    print(postflop_ground_truths)\n",
        "    print(postflop_predictions)"
      ],
      "metadata": {
        "id": "PujO8NrNkzEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}