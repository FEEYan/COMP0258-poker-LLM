{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8a461541ab4492fb6a9ea3ad7c8418e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_513537cafc7e4975bd35ed5fbe7755b7",
              "IPY_MODEL_103a0554e01d42c5b1c9fa43a2e89e64",
              "IPY_MODEL_de2fe6227d9f49188b81a2f3e9ea76c9"
            ],
            "layout": "IPY_MODEL_cd93395928b74bbfb88d7131adae1ad3"
          }
        },
        "513537cafc7e4975bd35ed5fbe7755b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aed9603fe194c68b04ed7da5e64468f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_494e67ae294f4edf92fe39f4b82fabd9",
            "value": "Downloadingâ€‡shards:â€‡100%"
          }
        },
        "103a0554e01d42c5b1c9fa43a2e89e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195341f6d18b4e11a94a64859611abdf",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35160a74c28a4227b132218884832e13",
            "value": 2
          }
        },
        "de2fe6227d9f49188b81a2f3e9ea76c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2044ac03a85146af8b3ad647ef3a5fe1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eab80abbfd114413ba4036274611919b",
            "value": "â€‡2/2â€‡[01:58&lt;00:00,â€‡60.16s/it]"
          }
        },
        "cd93395928b74bbfb88d7131adae1ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aed9603fe194c68b04ed7da5e64468f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494e67ae294f4edf92fe39f4b82fabd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195341f6d18b4e11a94a64859611abdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35160a74c28a4227b132218884832e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2044ac03a85146af8b3ad647ef3a5fe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab80abbfd114413ba4036274611919b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f0eb934fa1e4efabda3d6ba94d407e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24deeda905534a54b91426138d5d1cd0",
              "IPY_MODEL_fb565ab2ea0943c99f86617d203788fb",
              "IPY_MODEL_17496d9e10854f2489625ff2c4ebfb9a"
            ],
            "layout": "IPY_MODEL_0b175bd40882492289674057ee1b34b5"
          }
        },
        "24deeda905534a54b91426138d5d1cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0936fde92a3e48f9bde9673f56158957",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6dc7425b541d4daabe871bf87d79b474",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "fb565ab2ea0943c99f86617d203788fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c604eb25492a42679358a9ec35ec135b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6473e245a16c425ea8d2958b66a241a8",
            "value": 2
          }
        },
        "17496d9e10854f2489625ff2c4ebfb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50445a83182847aeab7f88d7754dc94b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4829675dab7048338e93a98dbfbf57cf",
            "value": "â€‡2/2â€‡[00:45&lt;00:00,â€‡22.66s/it]"
          }
        },
        "0b175bd40882492289674057ee1b34b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0936fde92a3e48f9bde9673f56158957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dc7425b541d4daabe871bf87d79b474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c604eb25492a42679358a9ec35ec135b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6473e245a16c425ea8d2958b66a241a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50445a83182847aeab7f88d7754dc94b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4829675dab7048338e93a98dbfbf57cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weber50432/COMP0258-poker-LLM/blob/master/colab/model_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEZZKaYBbbP9",
        "outputId": "7460c107-9151-4d08-e685-fd1c48b94f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# Define the path to the models directory in Google Drive\n",
        "models_dir = '/content/drive/MyDrive/models'\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(models_dir):\n",
        "    # If it doesn't exist, create it\n",
        "    os.makedirs(models_dir)\n",
        "output_dir = '/content/drive/MyDrive/outputs'\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "    # If it doesn't exist, create it\n",
        "    os.makedirs(output_dir)\n",
        "data_dir = '/content/drive/MyDrive/data'\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(data_dir):\n",
        "    # If it doesn't exist, error log\n",
        "    print(\"data directory not found\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Normally using pip install unsloth is enough\n",
        "\n",
        "if True:\n",
        "    # Temporarily as of Jan 31st 2025, Colab has some issues with Pytorch\n",
        "    # Using pip install unsloth will take 3 minutes, whilst the below takes <1 minute:\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "RBTSzur4cKNi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from tqdm import tqdm\n",
        "from transformers import TextStreamer\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "QOp85ydzdg9i",
        "outputId": "4b6a2222-6c5e-4fa4-ade6-ee002348f8aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "usning_custom_dataset = True\n",
        "models_dir = \"unsloth\"\n",
        "pretrained_model_name = \"qwen2.5-14b-instruct-bnb-4bit\"\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n"
      ],
      "metadata": {
        "id": "cACep_-6dZrq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = f\"{models_dir}/{pretrained_model_name}\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "# prompt = You MUST copy from above!\n",
        "prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    prompt.format(\n",
        "        \"You are a specialist in playing 6-handed No Limit Texas Holdem. The following will be a game scenario and you need to make the optimal decision.\\n\\nHere is a game summary:\\n\\nThe small blind is 0.5 chips and the big blind is 1 chips. Everyone started with 100 chips.\\nThe player positions involved in this game are UTG, HJ, CO, BTN, SB, BB.\\nIn this hand, your position is CO, and your holding is [Ace of Heart and King of Heart].\\nYou currently have High Card(Ace-high).\\nBefore the flop, CO raise 2.3, and BB raise 13.5. Assume that all other players that is not mentioned folded.\\n\\nNow it is your turn to make a move.\\nTo remind you, the current pot size is 16.3 chips, and your holding is [Ace of Heart and King of Heart].\\n\\nDecide on an action based on the strength of your hand on this board, your position, and actions before you. Do not explain your answer.\\nYour optimal action is:\"\n",
        "        \"\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655,
          "referenced_widgets": [
            "b8a461541ab4492fb6a9ea3ad7c8418e",
            "513537cafc7e4975bd35ed5fbe7755b7",
            "103a0554e01d42c5b1c9fa43a2e89e64",
            "de2fe6227d9f49188b81a2f3e9ea76c9",
            "cd93395928b74bbfb88d7131adae1ad3",
            "3aed9603fe194c68b04ed7da5e64468f",
            "494e67ae294f4edf92fe39f4b82fabd9",
            "195341f6d18b4e11a94a64859611abdf",
            "35160a74c28a4227b132218884832e13",
            "2044ac03a85146af8b3ad647ef3a5fe1",
            "eab80abbfd114413ba4036274611919b",
            "2f0eb934fa1e4efabda3d6ba94d407e0",
            "24deeda905534a54b91426138d5d1cd0",
            "fb565ab2ea0943c99f86617d203788fb",
            "17496d9e10854f2489625ff2c4ebfb9a",
            "0b175bd40882492289674057ee1b34b5",
            "0936fde92a3e48f9bde9673f56158957",
            "6dc7425b541d4daabe871bf87d79b474",
            "c604eb25492a42679358a9ec35ec135b",
            "6473e245a16c425ea8d2958b66a241a8",
            "50445a83182847aeab7f88d7754dc94b",
            "4829675dab7048338e93a98dbfbf57cf"
          ]
        },
        "id": "ltJnst1EcKtL",
        "outputId": "a87adf2c-dc70-4151-bc68-8164f81c51fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8a461541ab4492fb6a9ea3ad7c8418e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f0eb934fa1e4efabda3d6ba94d407e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### Instruction:\n",
            "You are a specialist in playing 6-handed No Limit Texas Holdem. The following will be a game scenario and you need to make the optimal decision.\n",
            "\n",
            "Here is a game summary:\n",
            "\n",
            "The small blind is 0.5 chips and the big blind is 1 chips. Everyone started with 100 chips.\n",
            "The player positions involved in this game are UTG, HJ, CO, BTN, SB, BB.\n",
            "In this hand, your position is CO, and your holding is [Ace of Heart and King of Heart].\n",
            "You currently have High Card(Ace-high).\n",
            "Before the flop, CO raise 2.3, and BB raise 13.5. Assume that all other players that is not mentioned folded.\n",
            "\n",
            "Now it is your turn to make a move.\n",
            "To remind you, the current pot size is 16.3 chips, and your holding is [Ace of Heart and King of Heart].\n",
            "\n",
            "Decide on an action based on the strength of your hand on this board, your position, and actions before you. Do not explain your answer.\n",
            "Your optimal action is:\n",
            "\n",
            "### Response:\n",
            "Fold\n",
            "\n",
            "### Rationale:\n",
            "Given the strength of the hand (AK), the aggressive raising by the big blind (BB) might indicate a very strong hand such as AA, KK, or QQ. Considering the size of the raise (13.5 chips), which is significantly larger than the initial raise (2.3 chips), it's likely the BB has a premium hand. Folding here minimizes potential losses against a likely strong hand. Allowing the BB to win the pot preflop is the best course of action given the circumstances. \n",
            "\n",
            "However, since explicit explanations were asked to be avoided, the provided response is simply \"Fold\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    # inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = prompt.format(instruction, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "if usning_custom_dataset:\n",
        "    # open a json file from data_dir\n",
        "    with open(f'{data_dir}/poker-preflop/preflop_1k_test_set_prompt_and_label.json', 'r') as f:\n",
        "            preflop_dataset = json.load(f)\n",
        "    print(f\"reading {len(preflop_dataset)} preflop data.\")\n",
        "    with open(f'{data_dir}/poker-postflop/postflop_10k_test_set_prompt_and_label.json', 'r') as f:\n",
        "            postflop_dataset = json.load(f)\n",
        "    print(f\"reading {len(postflop_dataset)} preflop data.\")\n",
        "else:\n",
        "    dataset = load_dataset(\"RZ412/PokerBench\", split = \"test\")\n",
        "    dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snSDRfbed9SB",
        "outputId": "b7d2950e-a6e0-4515-f286-d7b067a6a196"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading 1000 preflop data.\n",
            "reading 10000 preflop data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## testing a radom sample"
      ],
      "metadata": {
        "id": "7x9t6RMXk9eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not usning_custom_dataset:\n",
        "    print(\"Processing hg dataset.\")\n",
        "    index = random.randint(0, len(dataset))\n",
        "    print(\"Groud truth: \",dataset[index]['output'])\n",
        "    inputs = tokenizer([prompt.format(dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "else:\n",
        "    print(\"Processing custom dataset.\")\n",
        "    index = random.randint(0, len(preflop_dataset))\n",
        "    print(\"Groud truth: \",preflop_dataset[index]['output'])\n",
        "    inputs = tokenizer([prompt.format(preflop_dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "# text_streamer = TextStreamer(tokenizer)\n",
        "# outputs = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 10)\n",
        "outputs = model.generate(**inputs, max_new_tokens = 10)\n",
        "\n",
        "generated_text = tokenizer.batch_decode(outputs)[0]\n",
        "generated_text = generated_text.split(\"### Response:\")[1].strip()\n",
        "generated_text = generated_text.replace(EOS_TOKEN, \"\")\n",
        "print(\"Prediction: \",generated_text) # Print the generated text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DogBVbq7exfK",
        "outputId": "6388e53f-0752-45aa-93d3-49b7a458d263"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing custom dataset.\n",
            "Groud truth:  call\n",
            "Prediction:  Call (11 chips) to see the flop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not usning_custom_dataset:\n",
        "    ground_truths = []\n",
        "    predictions = []\n",
        "    for index in tqdm(range(len(dataset)), desc=\"Processing hg dataset\"):\n",
        "        # print(dataset[index]['output'])\n",
        "        ground_truths.append(dataset[index]['output'])\n",
        "        inputs = tokenizer([prompt.format(dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens = 10)\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "        response = response.split(\"### Response:\")[1].strip()\n",
        "        response = response.replace(EOS_TOKEN, \"\")\n",
        "        # print(response)\n",
        "        predictions.append(response)\n",
        "        # break\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "    \"Prediction\": predictions,\n",
        "    \"Ground Truth\": ground_truths\n",
        "    })\n",
        "    # Save the DataFrames to CSV files\n",
        "    results_df.to_csv(f\"{output_dir}/{pretrained_model_name}_total_predictions.csv\", index=False)\n",
        "\n",
        "else:\n",
        "    preflop_ground_truths = []\n",
        "    preflop_predictions = []\n",
        "    for index in tqdm(range(len(preflop_dataset)), desc=\"Processing custom preflop dataset\"):\n",
        "        # print(dataset[index]['output'])\n",
        "        preflop_ground_truths.append(preflop_dataset[index]['output'])\n",
        "        inputs = tokenizer([prompt.format(preflop_dataset[index]['instruction'],\"\")], return_tensors = \"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens = 10)\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "        response = response.split(\"### Response:\")[1].strip()\n",
        "        response = response.replace(EOS_TOKEN, \"\")\n",
        "        # print(response)\n",
        "        preflop_predictions.append(response)\n",
        "        # break\n",
        "    preflop_results_df = pd.DataFrame({\n",
        "    \"Prediction\": preflop_predictions,\n",
        "    \"Ground Truth\": preflop_ground_truths\n",
        "    })\n",
        "    preflop_results_df.to_csv(f\"{output_dir}/{pretrained_model_name}_preflop_predictions.csv\", index=False)\n",
        "\n",
        "\n",
        "    postflop_ground_truths = []\n",
        "    postflop_predictions = []\n",
        "    save_interval = 1000\n",
        "    output_file = f\"{output_dir}/{pretrained_model_name}_postflop_predictions.csv\"\n",
        "\n",
        "    for index in tqdm(range(len(postflop_dataset)), desc=\"Processing custom postflop dataset\"):\n",
        "        postflop_ground_truths.append(postflop_dataset[index]['output'])\n",
        "\n",
        "        inputs = tokenizer([prompt.format(postflop_dataset[index]['instruction'], \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens=10)\n",
        "        response = tokenizer.batch_decode(outputs)[0]\n",
        "        response = response.split(\"### Response:\")[1].strip()\n",
        "        response = response.replace(EOS_TOKEN, \"\")\n",
        "\n",
        "        postflop_predictions.append(response)\n",
        "\n",
        "        if (index + 1) % save_interval == 0 or (index + 1) == len(postflop_dataset):\n",
        "            postflop_results_df = pd.DataFrame({\n",
        "                \"Prediction\": postflop_predictions,\n",
        "                \"Ground Truth\": postflop_ground_truths\n",
        "            })\n",
        "            postflop_results_df.to_csv(output_file, index=False)\n",
        "            print(f\"Saved progress at iteration {index + 1}\")\n",
        "\n",
        "    print(\"Processing completed.\")"
      ],
      "metadata": {
        "id": "jslsYFrLkKYM",
        "outputId": "188bb61c-8b3a-407f-fdbb-f63512a822dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom preflop dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [27:03<00:00,  1.62s/it]\n",
            "Processing custom postflop dataset:  10%|â–ˆ         | 1000/10000 [30:26<4:40:41,  1.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  20%|â–ˆâ–ˆ        | 2000/10000 [1:00:50<4:07:03,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  30%|â–ˆâ–ˆâ–ˆ       | 3000/10000 [1:31:19<3:36:35,  1.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4000/10000 [2:01:47<3:04:50,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved progress at iteration 4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing custom postflop dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 4528/10000 [2:17:53<2:48:59,  1.85s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not usning_custom_dataset:\n",
        "    print(ground_truths)\n",
        "    print(predictions)\n",
        "else:\n",
        "    print(preflop_ground_truths)\n",
        "    print(preflop_predictions)\n",
        "    print(postflop_ground_truths)\n",
        "    print(postflop_predictions)"
      ],
      "metadata": {
        "id": "PujO8NrNkzEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}